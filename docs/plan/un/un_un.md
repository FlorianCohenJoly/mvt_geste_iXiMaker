---
sidebar_position: 2
---

# 1.2 Exemple de “gestes” dans les jeux vidéo non-VR


Avant l'avènement de la réalité virtuelle et de ses dispositifs de suivi de mouvements sophistiqués, les jeux vidéo ont exploré diverses manières de simuler des actions et des intentions par le biais d'interfaces plus traditionnelles telles que le clavier, la souris et, plus tard, les capteurs de mouvements. Bien que ne reproduisant pas fidèlement la complexité et la nuance des interactions manuelles réelles, ces exemples pionniers ont jeté les bases de la réflexion sur la manière de traduire des actions physiques en commandes numériques, et d'offrir une forme d'expressivité gestuelle au joueur.

**[Arx Fatalis](https://fr.wikipedia.org/wiki/Arx_Fatalis)** : Traçage de sorts magiques avec la souris. Sorti en 2002, Arx Fatalis proposait un système de lancement de sorts unique et immersif pour l'époque. Au lieu de simplement sélectionner un sort dans un menu, le joueur devait effectuer une série de mouvements précis avec la souris pour dessiner des runes à l'écran. Chaque rune correspondait à une partie d'un sort, et la combinaison et la précision du tracé déterminaient le sort lancé. Ce système demandait une certaine dextérité et mémorisation de la part du joueur, créant un lien plus engageant entre l'intention du joueur et l'action à l'écran. Bien que limité à un plan 2D, ce mécanisme préfigurait l'idée d'utiliser des mouvements manuels pour interagir avec l'environnement virtuel, en allant au-delà du simple pointage et clic.

**[Black & White 1](https://fr.wikipedia.org/wiki/Black_and_White_(jeu_vid%C3%A9o)) & [2](https://fr.wikipedia.org/wiki/Black_and_White_2)** : Interactions gestuelles pour diriger une créature. La série Black & White, dont le premier opus est sorti en 2001, offrait une approche novatrice de la simulation de divinité. Le joueur incarnait une main divine capable d'interagir directement avec le monde et ses habitants. Si les clics et les déplacements de la souris permettaient des actions générales, le jeu introduisait également des "gestes" plus expressifs pour influencer et éduquer la créature divine sous leur tutelle. Par exemple, caresser la créature avec le curseur pouvait la récompenser et l'encourager, tandis que la frapper pouvait la punir. Ces interactions, bien que rudimentaires en termes de suivi de mouvements, permettaient une forme de communication non verbale et intuitive avec l'entité virtuelle, renforçant le lien émotionnel et l'immersion dans le rôle de dieu bienveillant (ou malveillant).

**[Fruit Ninja Kinect](https://www.jeuxvideo.com/jeux/xbox-360/00041025-fruit-ninja-kinect.htm)** : Mouvements corporels captés par Kinect. Avec l'avènement des capteurs de mouvements comme Kinect pour la Xbox 360 (sorti en 2010), une nouvelle dimension d'interaction gestuelle a émergé. Fruit Ninja Kinect est un exemple emblématique de cette transition. Le jeu transposait le concept simple de trancher des fruits en vol, initialement contrôlé par l'écran tactile, en une expérience où les mouvements des bras et des mains du joueur étaient directement traduits en actions dans le jeu. Agiter les bras pour couper une multitude de fruits, réaliser des mouvements rapides et précis pour éviter les bombes, offrait une immersion physique bien supérieure aux contrôles traditionnels. Bien que ne se concentrant pas sur la manipulation d'objets techniques complexes, Fruit Ninja Kinect a démontré le potentiel des interfaces basées sur le mouvement pour rendre les interactions ludiques et engageantes, et a ouvert la voie à l'exploration de gestes plus sophistiqués dans d'autres contextes.

Autres exemples notables :

**[Wii Sports (Nintendo Wii, 2006)](https://fr.wikipedia.org/wiki/Wii_Sports)** : La télécommande Wii Remote, avec ses capteurs de mouvements, permettait des simulations gestuelles pour des sports comme le tennis (imiter un swing de raquette), le bowling (mimer un lancer de boule) ou le golf (simuler un swing de club). Bien que simplifiées, ces interactions offraient une forme d'engagement physique et une immersion nouvelle pour un large public.

**[Heavy Rain (PlayStation 3, 2010)](https://fr.wikipedia.org/wiki/Heavy_Rain)** : Ce jeu narratif mettait l'accent sur des interactions contextuelles et des "quick time events" (QTE) qui demandaient au joueur d'effectuer des mouvements spécifiques avec les sticks analogiques et les boutons de la manette pour réaliser des actions à l'écran, comme tourner une clé, ouvrir une porte avec force ou se battre. Bien que parfois critiquées pour leur caractère scripté, ces séquences tentaient de connecter les actions du joueur à l'environnement virtuel d'une manière plus directe.


Ces exemples, bien que n'atteignant pas le niveau de fidélité et de complexité des interactions manuelles en VR, illustrent une progression constante dans la recherche de méthodes pour impliquer le corps et les mouvements du joueur dans l'expérience vidéoludique. Ils soulignent l'intérêt constant des développeurs à dépasser les limites des interfaces traditionnelles pour offrir des interactions plus intuitives et immersives, préparant ainsi le terrain pour les avancées significatives qu'apporterait la réalité virtuelle.